{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9625b6-d216-465b-8259-9333d7269d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# FILE = Path('./')\n",
    "ROOT = Path('/home/rodrigo/Documents/usp/tcc/yolov5/')  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
    "                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec51f9b2-3654-4328-a932-4fb2a5a5148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadFollower:\n",
    "    def __init__(self, x_last=0, y_last=0, threshold=100):\n",
    "        self.x_last = x_last\n",
    "        self.y_last = y_last\n",
    "        self.setpoint = (0.5, 0.5)\n",
    "        self.threshold = threshold\n",
    "        self.angle = 0.0\n",
    "        self.angle_last = 0.0\n",
    "        self.start_sliders()\n",
    "        # self.start_robot()\n",
    "\n",
    "    # def start_robot(self):\n",
    "    #     self.robot = Robot()\n",
    "\n",
    "    def start_sliders(self):\n",
    "        self.speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "        self.steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "        self.steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.25, description='steering kd')\n",
    "        self.steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "        self.x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "        self.y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "        self.steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "        self.speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "        self.left_motor = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='left motor')\n",
    "        self.right_motor = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='right motor')\n",
    "\n",
    "    def display_control_sliders(self):\n",
    "        display(\n",
    "            self.speed_gain_slider,\n",
    "            self.steering_gain_slider,\n",
    "            self.steering_dgain_slider,\n",
    "            self.steering_bias_slider\n",
    "        )\n",
    "\n",
    "    def display_monitor_sliders(self):\n",
    "        display(self.y_slider, self.speed_slider)\n",
    "        display(self.x_slider, self.steering_slider)\n",
    "        display(self.left_motor, self.right_motor)\n",
    "\n",
    "    def execute(self, image):\n",
    "        xy, image = self.update(image)\n",
    "        # image = change['new']\n",
    "        # xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "        x = xy[0]\n",
    "        y = (0.5 - xy[1]) / 2.0\n",
    "\n",
    "        self.x_slider.value = x\n",
    "        self.y_slider.value = y\n",
    "\n",
    "        self.speed_slider.value = self.speed_gain_slider.value\n",
    "\n",
    "        self.angle = np.arctan2(x, y)\n",
    "        pid = self.angle * self.steering_gain_slider.value\\\n",
    "              + (self.angle - self.angle_last) * self.steering_dgain_slider.value\n",
    "        self.angle_last = self.angle\n",
    "\n",
    "        self.steering_slider.value = pid + self.steering_bias_slider.value\n",
    "\n",
    "        # robot.left_motor.value = \n",
    "        self.left_motor.value = max(\n",
    "            min(self.speed_slider.value + self.steering_slider.value, 1.0),\n",
    "            0.0\n",
    "        )\n",
    "        self.right_motor.value = max(\n",
    "            min(self.speed_slider.value - self.steering_slider.value, 1.0),\n",
    "            0.0\n",
    "        )\n",
    "        return image\n",
    "\n",
    "    def update(self, image):\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        roi = [[250,-1],[0,-1]]\n",
    "        image = image[roi[0][0]:roi[0][1], roi[1][0]:roi[1][1]]\n",
    "        # image = image[300:415, :]  # Region Of Interest\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # print(image.shape)\n",
    "        (thresh, image) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        # Blackline = cv2.inRange(image, (0,0,0), (self.threshold,self.threshold,self.threshold))\n",
    "        Blackline = cv2.inRange(image, 0, thresh)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        Blackline = cv2.erode(Blackline, kernel, iterations=5)\n",
    "        Blackline = cv2.dilate(Blackline, kernel, iterations=9)\t\n",
    "        contours_blk, hierarchy_blk = cv2.findContours(Blackline.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        contours_blk_len = len(contours_blk)\n",
    "        if contours_blk_len > 0 :\n",
    "            if contours_blk_len == 1 :\n",
    "                blackbox = cv2.minAreaRect(contours_blk[0])\n",
    "            else:\n",
    "                canditates=[]\n",
    "                off_bottom = 0\t   \n",
    "                for con_num in range(contours_blk_len):\t\t\n",
    "                    blackbox = cv2.minAreaRect(contours_blk[con_num])\n",
    "                    (x_min, y_min), (w_min, h_min), ang = blackbox\t\t\n",
    "                    box = cv2.boxPoints(blackbox)\n",
    "                    (x_box,y_box) = box[0]\n",
    "                    if y_box > 358 :\t\t \n",
    "                        off_bottom += 1\n",
    "                    canditates.append((y_box,con_num,x_min,y_min))\t\t\n",
    "                canditates = sorted(canditates)\n",
    "                if off_bottom > 1:\t    \n",
    "                    canditates_off_bottom=[]\n",
    "                    for con_num in range ((contours_blk_len - off_bottom), contours_blk_len):\n",
    "                        (y_highest,con_highest,x_min, y_min) = canditates[con_num]\t\t\n",
    "                        total_distance = (abs(x_min - self.x_last)**2 + abs(y_min - self.y_last)**2)**0.5\n",
    "                        canditates_off_bottom.append((total_distance,con_highest))\n",
    "                    canditates_off_bottom = sorted(canditates_off_bottom)         \n",
    "                    (total_distance,con_highest) = canditates_off_bottom[0]         \n",
    "                    blackbox = cv2.minAreaRect(contours_blk[con_highest])\t   \n",
    "                else:\t\t\n",
    "                    (y_highest,con_highest,x_min, y_min) = canditates[contours_blk_len-1]\n",
    "                    blackbox = cv2.minAreaRect(contours_blk[con_highest])\n",
    "            (x_min, y_min), (w_min, h_min), ang = blackbox\n",
    "            self.x_last = x_min\n",
    "            self.y_last = y_min\n",
    "            box = cv2.boxPoints(blackbox)\n",
    "            box = np.int0(box)\n",
    "            cv2.drawContours(image,[box],0,(0,0,0),3)\n",
    "            cv2.line(image, (int(x_min),0 ), (int(x_min),50 ), (0,0,0),3)\n",
    "            cv2.circle(image, (image.shape[1]//2, image.shape[0]//2), 5, (0,0,0), 3)\n",
    "            cv2.circle(image, (int(x_min), int(y_min)), 5, (255,255,255), 3)\n",
    "            xy = [(x_min - image.shape[1]/2.0) / image.shape[1], (y_min - image.shape[0]/2.0) / image.shape[0]]\n",
    "        else:\n",
    "            xy = [0.0, 0.0]\n",
    "            # error = 0\n",
    "        return xy, image\n",
    "        # return image, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0843d68-74d1-4c68-a3c5-ea199813097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "weights = ROOT / 'best.pt'  # model.pt path(s)\n",
    "source = 0  # file/dir/URL/glob, 0 for webcam\n",
    "imgsz = [416]  # inference size (pixels)\n",
    "conf_thres = 0.25  # confidence threshold\n",
    "iou_thres = 0.45  # NMS IOU threshold\n",
    "max_det = 1000  # maximum detections per image\n",
    "device = ''  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "view_img = False  # show results\n",
    "save_txt = False  # save results to *.txt\n",
    "save_conf = False  # save confidences in --save-txt labels\n",
    "save_crop = False  # save cropped prediction boxes\n",
    "nosave = False  # do not save images/videos\n",
    "classes = None  # filter by class: --class 0, or --class 0 2 3\n",
    "agnostic_nms = False  # class-agnostic NMS\n",
    "augment = False  # augmented inference\n",
    "visualize = False  # visualize features\n",
    "update = False  # update all models\n",
    "project = ROOT / 'runs/detect'  # save results to project/name\n",
    "name = 'exp'  # save results to project/name\n",
    "exist_ok = False  # existing project/name ok, do not increment\n",
    "line_thickness = 3  # bounding box thickness (pixels)\n",
    "hide_labels = False  # hide labels\n",
    "hide_conf = False  # hide confidences\n",
    "half = False  # use FP16 half-precision inference\n",
    "dnn = False  # use OpenCV DNN for ONNX inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ec057f-5cf5-4915-ba94-2c8ecd41d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsz *= 2 if len(imgsz) == 1 else 1  # expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b553189-db41-4413-b833-c8df6fb55868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[416, 416]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ba2a57-cca9-4481-b739-2408c7d72c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = str(source)\n",
    "save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n",
    "is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "if is_url and is_file:\n",
    "    source = check_file(source)  # download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda39b7f-942e-45c9-ae71-41471bdf5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
    "(save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea919bf3-ace9-4ba0-abc8-fc7086967dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v6.0-83-gcc91ae5 torch 1.10.0+cu102 CUDA:0 (NVIDIA GeForce MX150, 4042MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7031701 parameters, 0 gradients, 15.9 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "device = select_device(device)\n",
    "model = DetectMultiBackend(weights, device=device, dnn=dnn)\n",
    "stride, names, pt, jit, onnx = model.stride, model.names, model.pt, model.jit, model.onnx\n",
    "imgsz = check_img_size(imgsz, s=stride)  # check image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "729733b8-fe42-45e5-bc6a-f39ee5908e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[416, 416]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583b57a9-02dd-46d1-a168-f172022a144a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c602dbd-2053-41b8-afe0-357aeae9c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "view_img = check_imshow()\n",
    "cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt and not jit)\n",
    "bs = len(dataset)  # batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "810e414e-9a08-4e9c-ab7c-a8a2cfe9f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path, vid_writer = [None] * bs, [None] * bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13797ba9-f471-4288-8656-6fc0fb2e516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pt and device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, *imgsz).to(device).type_as(next(model.model.parameters())))  # warmup\n",
    "dt, seen = [0.0, 0.0, 0.0], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4a3057f-467c-4777-a4c5-4dc0ea112995",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_follower = RoadFollower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "131ce5c2-af42-417e-990d-b52e5195f7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104ebe76e1734b83b6cf5986a49eff0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765473764ebd4a7ab4da14489110b298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfd1fa0dbb947d09880f24d6177541d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.25, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b83837305c418794400abb97ef65b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "road_follower.display_control_sliders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e18c3332-cd98-4b78-ab83-b3bcae0159bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca2c24c9d8a4a8a91005291d15341d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034e447fed284483a4696e25430631fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed', max=1.0, orientation='vertical')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4e82d1fa794460a0f485625194a53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb5bc34bb0a4167a5e8b1a9ac6c5f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc394e387c2468d8ea2882e7dcf22ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='left motor', max=1.0, orientation='vertical')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13e6854f20b4f65a7bbba5691e89ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='right motor', max=1.0, orientation='vertical')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "road_follower.display_monitor_sliders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "375688d3-815a-44f4-a447-3ecdc037392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for path, im, im0s, vid_cap, s in dataset:\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Inference\n",
    "        # visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "        pred = model(im, augment=augment, visualize=False)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "        # print(\"=\"*50)\n",
    "        # print(\"PRED FIRST:\\n\", pred)\n",
    "\n",
    "        # NMS\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        # print(\"PRED NMS:\\n\", pred)\n",
    "        # print(\"=\"*50)\n",
    "        dt[2] += time_sync() - t3\n",
    "        im0 = im0s.copy()\n",
    "        det = pred[0]\n",
    "        for c in det[:, -1].unique():\n",
    "            n = (det[:, -1] == c).sum()  # detections per class\n",
    "            s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "        # image = np.asarray(im.cpu())\n",
    "        image = im[0].cpu().permute(1, 2, 0).numpy() * 255\n",
    "        image = np.asarray(image).astype('uint8').copy()\n",
    "        # image, _ = road_follower.update(image)\n",
    "        image = road_follower.execute(image)\n",
    "        cv2.putText(image,str(s),(10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        cv2.imshow(\"Test\", image)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "except:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f80d533e-f8eb-4c34-8ae1-5720a6d2edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
